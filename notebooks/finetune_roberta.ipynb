{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_6er0kWM3RP"
   },
   "source": [
    "# Project: Sentiment Analysis on Product Reviews\n",
    "\n",
    "- **Dataset**: [Women's Clothing E-Commerce Reviews](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews)\n",
    "- **HuggingFace Model:** [cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bqCFyN1mhAT"
   },
   "source": [
    "# Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0j3pTAfM3RQ"
   },
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DSpt938tM3RQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification\n",
    "import os\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft-iJ95uM3RR"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7rsvAylgM3RR"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\" #Where pre-trained model and tokenizer is\n",
    "NUM_LABELS = 3 #positive, neutral, and negative\n",
    "\n",
    "# Tokenization\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Random seed\n",
    "SEED = 42\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# Early stopping patience\n",
    "PATIENCE = 3\n",
    "\n",
    "# Create timestamped run directory\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = f\"runs/run_{TIMESTAMP}\"\n",
    "CHECKPOINT_DIR = os.path.join(RUN_DIR, \"checkpoints\")\n",
    "LOG_DIR = os.path.join(RUN_DIR, \"logs\")\n",
    "MODEL_DIR = os.path.join(RUN_DIR, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isZ1vMKFM3RR",
    "outputId": "53e0f611-26ef-410b-8c90-25a14844b60b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run directory: runs/run_20260101_150332\n",
      "Configuration saved to: runs/run_20260101_150332/config.json\n"
     ]
    }
   ],
   "source": [
    "# Create all directories\n",
    "for dir_path in [CHECKPOINT_DIR, LOG_DIR, MODEL_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(f\"Run directory: {RUN_DIR}\")\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"max_len\": MAX_LEN,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"num_labels\": NUM_LABELS,\n",
    "    \"patience\": PATIENCE,\n",
    "    \"seed\": SEED,\n",
    "    \"timestamp\": TIMESTAMP\n",
    "}\n",
    "\n",
    "config_path = os.path.join(RUN_DIR, \"config.json\")\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(f\"Configuration saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMvwC7pKM3RS"
   },
   "source": [
    "## Setting random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vOJbBwbqM3RS"
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qu-ACkD1M3RS"
   },
   "source": [
    "## Load Dataset\n",
    "Download and read dataset from nicapotato/womens-ecommerce-clothing-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "aU4LRNDyM3RS",
    "outputId": "b881d6ee-2445-4b32-c4c7-46144b473ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (23486, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Title                                        Review Text  \\\n",
       "0                      NaN  Absolutely wonderful - silky and sexy and comf...   \n",
       "1                      NaN  Love this dress!  it's sooo pretty.  i happene...   \n",
       "2  Some major design flaws  I had such high hopes for this dress and reall...   \n",
       "3         My favorite buy!  I love, love, love this jumpsuit. it's fun, fl...   \n",
       "4         Flattering shirt  This shirt is very flattering to all due to th...   \n",
       "\n",
       "   Rating  Recommended IND  \n",
       "0       4                1  \n",
       "1       5                1  \n",
       "2       3                0  \n",
       "3       5                1  \n",
       "4       5                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"nicapotato/womens-ecommerce-clothing-reviews\") #Get dataset\n",
    "df = pd.read_csv(path + '/Womens Clothing E-Commerce Reviews.csv') #Read dataset\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"Clothing ID\", \"Age\", \"Positive Feedback Count\", \\\n",
    "\"Division Name\", \"Department Name\", \"Class Name\"]) #removing all data not used for sentiment analysis\n",
    "\n",
    "#For review\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJtpydhEM3RT"
   },
   "source": [
    "## Data Cleaning & Text Preparation\n",
    "Remove reviews that lack text and standardize review format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTEIrlliM3RT",
    "outputId": "c43edcfc-b4a9-4936-9cda-3c4d6da1c570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset: 22631 reviews\n"
     ]
    }
   ],
   "source": [
    "# Drop empty reviews\n",
    "df = df.dropna(subset=[\"Title\", \"Review Text\"], how='all') #To filter out completely empty reviews\n",
    "df = df[(df[\"Review Text\"].str.strip() != \"\") & (df[\"Title\"].str.strip() != \"\")] #In case both are whitespace\n",
    "\n",
    "# Combine title and review text into text column\n",
    "df[\"text\"] = df[\"Title\"].fillna(\"\").str.strip() + \". \" + df[\"Review Text\"].fillna(\"\").str.strip()\n",
    "\n",
    "# Remove very short reviews\n",
    "df = df[df[\"text\"].str.split().str.len() >= 5]\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Cleaned dataset: {len(df)} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMHY3Y9bM3RT"
   },
   "source": [
    "## Sentiment Label Creation\n",
    "Translate ratings of 4 or 5 stars to positive (2), 1 or 2 stars to negative (0), and 3 stars to neutral (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwiPKbZbM3RT",
    "outputId": "894e210c-9cbe-4770-ffc0-7fc5ed84cb9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "sentiment\n",
      "0     2370\n",
      "1     2822\n",
      "2    17439\n",
      "Name: count, dtype: int64\n",
      "\n",
      "0=negative, 1=neutral, 2=positive\n"
     ]
    }
   ],
   "source": [
    "#Translate star rating to sentiment\n",
    "def rating_to_sentiment(r):\n",
    "    if r <= 2:\n",
    "        return 0  # negative\n",
    "    elif r == 3:\n",
    "        return 1  # neutral\n",
    "    else:\n",
    "        return 2  # positive\n",
    "\n",
    "#Adds sentiment value to all data\n",
    "df[\"sentiment\"] = df[\"Rating\"].apply(rating_to_sentiment)\n",
    "\n",
    "print(\"Label distribution:\")\n",
    "print(df[\"sentiment\"].value_counts().sort_index()) #How many of each label\n",
    "print(\"\\n0=negative, 1=neutral, 2=positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeuXnW63M3RT"
   },
   "source": [
    "## Train / Validation / Test Split (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHgvSIWCM3RU",
    "outputId": "4d43abff-e0da-45e5-cc5f-b3ae3eb3a931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 18104 samples\n",
      "Val:   2263 samples\n",
      "Test:  2264 samples\n"
     ]
    }
   ],
   "source": [
    "X = df[\"text\"]\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "# Shuffle indices\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split points\n",
    "train_end = int(0.8 * len(X))\n",
    "val_end = int(0.9 * len(X))\n",
    "\n",
    "#Seperate data into training, validation, and testing\n",
    "train_idx = indices[:train_end]\n",
    "val_idx = indices[train_end:val_end]\n",
    "test_idx = indices[val_end:]\n",
    "\n",
    "X_train, y_train = X.iloc[train_idx].values, y.iloc[train_idx].values\n",
    "X_val, y_val = X.iloc[val_idx].values, y.iloc[val_idx].values\n",
    "X_test, y_test = X.iloc[test_idx].values, y.iloc[test_idx].values\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Val:   {len(X_val)} samples\")\n",
    "print(f\"Test:  {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Et7KIXdcM3RU"
   },
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287,
     "referenced_widgets": [
      "406d84268fd246aa9a8b4c2c64d44e40",
      "9d01486ee5364e3ba50dacf3545f533b",
      "b470310325344c22abef0c62dfb377d3",
      "23fe4a40970845de9c88ecb3aaafdbbf",
      "d46af5759d0e4481bfd18dd1db25bc8e",
      "17d7a072d9d8420aa64b7e77ef50af16",
      "4157f243d68b4059b4513f9a6f450bbb",
      "42cc0c86475f4443af118e155d568914",
      "464f3a8667164ce0b57a5af0df79a2a9",
      "41446d6b4312486a86dc1bd19392e1e5",
      "36ea67d707ce4da49893be29741f2a67",
      "fadac0977ff447f0927ee2fd52e73b2e",
      "46351aa7470c4142a32397c534589ec7",
      "d2c54eda93b24dc9850f27a5e4b3a363",
      "6608feb5770e45baac5d31cc120b0ef8",
      "2b12a3c8ce474ecdbb2bb92b28806fa2",
      "d9543e82d1124ffe9f855e1b40ca21f1",
      "8bf258af954a487cbd21966f1daf0b70",
      "2a989d06998847eda5764da49a610f35",
      "cf310611a3764097834d52c76097aad3",
      "7337e7b92c8b4ba0bf7c5bba53a73327",
      "19b20a6fe80f41d69cb61a55b80a7c80",
      "e7ff21a1b2924472a38cc87162dabae0",
      "84bfd6bada01486aaf476497e45b034e",
      "8b3cf55747ae46ceb7754fac0fdfd5c1",
      "260660026b5846dbbc35bd10a63c63af",
      "35335e46e82743f2b940c0566a929a79",
      "ba11fb54961543e2b5769dd14af025cb",
      "4e901859dc3a463db0a2720501332c88",
      "07e67538b9a646b7b21478ca149f452f",
      "5fb4b3ec8bb747078734c293aef40b12",
      "aac51799390f4b558aec3c74d7bb2ea1",
      "92f33d7a1c14462583fc0efed46f83ba",
      "a7262ef97a2d4d3698b0f13d2b1148f7",
      "0ccc3db8c0bd4324bdbdae4befd016ba",
      "db7de24f635a44448e413dcad1a00ea0",
      "f85efee187924b6aa1785ad34d29c981",
      "c67ec9d310e841c8a2d3065efcd6a686",
      "b5e4627e623f401194e08db8c207b311",
      "d9c6e612a66f4e61a124805f822820a3",
      "2a0401d68f4a40bcbbf29d19556fe8d6",
      "37a6c10691e840dd8cb2d8446f601664",
      "4c236dd5f385446a9cd59a77c4b3efd7",
      "70a0c8c741eb4e3d8b85ee8ac46c8c72"
     ]
    },
    "id": "JqVhs1i6M3RU",
    "outputId": "00faadb7-92fb-4e0d-dd98-0a26ee9796ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: cardiffnlp/twitter-roberta-base-sentiment-latest\n"
     ]
    }
   ],
   "source": [
    "#Load tokenizer from source of MODEL_NAME\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"Tokenizer loaded: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBgQjyOdM3RU"
   },
   "source": [
    "## Define Test Reviews for Before/After Comparison\n",
    "\n",
    "These exact reviews will be used to compare baseline vs fine-tuned performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--9GCSw8M3RU",
    "outputId": "6bad6052-97ad-4d00-9b10-91b794c50edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 8 test reviews for before/after comparison\n"
     ]
    }
   ],
   "source": [
    "TEST_REVIEWS = [\n",
    "    # Clearly negative\n",
    "    \"This is the worst product I've ever bought. Complete waste of money.\",\n",
    "\n",
    "    # Clearly positive\n",
    "    \"Absolutely love this dress! Perfect fit and beautiful fabric. Highly recommend!\",\n",
    "\n",
    "    # Mixed/Neutral - quality good but not my style\n",
    "    \"This dress isn't really my style, but the fabric feels good and high quality.\",\n",
    "\n",
    "    # Disappointed expectations\n",
    "    \"I was really excited about this dress, but the fabric feels cheap and it fits oddly.\",\n",
    "\n",
    "    # Long-time user with price complaint\n",
    "    \"Have used this brand for decades and while it is our favorite, the increase in prices over the years is ridiculous.\",\n",
    "\n",
    "    # Detailed positive review\n",
    "    \"I'm really enjoying this blush. Application is smooth and easy. Long lasting color throughout the day.\",\n",
    "\n",
    "    # Product didn't meet claims\n",
    "    \"Went to the beach with this water bottle full of ice. By 2pm my water was warm! Does not last as described.\",\n",
    "\n",
    "    # Sizing issue but liked the product\n",
    "    \"Beautiful sweater but runs very small. Had to return for a larger size. The quality is excellent though.\"\n",
    "]\n",
    "\n",
    "# Expected sentiments (human judgment)\n",
    "EXPECTED_LABELS = [\n",
    "    \"negative\",   # worst product\n",
    "    \"positive\",   # absolutely love\n",
    "    \"neutral\",    # not my style but good quality\n",
    "    \"negative\",   # disappointed\n",
    "    \"negative\",   # price complaint\n",
    "    \"positive\",   # enjoying, smooth, long lasting\n",
    "    \"negative\",   # didn't meet claims\n",
    "    \"neutral\"     # issue but good quality\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(TEST_REVIEWS)} test reviews for before/after comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2GzOQJzM3RU"
   },
   "source": [
    "---\n",
    "\n",
    "# PART 1: Baseline Evaluation (Before Fine-Tuning)\n",
    "\n",
    "Load the pre-trained model and evaluate on test reviews without any fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcCHTj80M3RU",
    "outputId": "2e9ac994-1751-414d-e892-a2c87d6cc347"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model loaded: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "This model was trained on ~58M tweets for sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model from source of MODEL_NAME (NO fine-tuning yet)\n",
    "baseline_model = TFRobertaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "print(f\"Baseline model loaded: {MODEL_NAME}\")\n",
    "print(\"This model was trained on ~58M tweets for sentiment analysis.\")\n",
    "\n",
    "from tf_keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "baseline_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "final_model_path = os.path.join(MODEL_DIR, \"baseline_model.h5\")\n",
    "baseline_model.save_pretrained(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "y1SEz3WSM3RU"
   },
   "outputs": [],
   "source": [
    "LABEL_MAP = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "#Function to detects a model's probability of each label for the text\n",
    "def predict_sentiment(model, text):\n",
    "    \"\"\"Predict sentiment for a single text.\"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "    logits = model(**inputs).logits\n",
    "    probs = tf.nn.softmax(logits, axis=1).numpy()[0]\n",
    "    pred_idx = np.argmax(probs)\n",
    "\n",
    "    return {\n",
    "        \"label\": LABEL_MAP[pred_idx], #prediction\n",
    "        \"confidence\": float(probs[pred_idx]), #prediction label probability\n",
    "        \"probabilities\": {\n",
    "            \"negative\": float(probs[0]), #probability of negative label\n",
    "            \"neutral\": float(probs[1]), #probability of neutral label\n",
    "            \"positive\": float(probs[2]) #probability of positive label\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbI-CT3nM3RV"
   },
   "source": [
    "### Evaluation - Before Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5VsI08gM3RV",
    "outputId": "f995f300-01e3-4e5f-f8d8-db9a8efde882"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review 1: \"This is the worst product I've ever bought. Complete waste o...\"\n",
      "  Expected: negative\n",
      "  Baseline: negative (confidence: 35.20%) ✓\n",
      "\n",
      "Review 2: \"Absolutely love this dress! Perfect fit and beautiful fabric...\"\n",
      "  Expected: positive\n",
      "  Baseline: neutral (confidence: 35.07%) ✗\n",
      "\n",
      "Review 3: \"This dress isn't really my style, but the fabric feels good ...\"\n",
      "  Expected: neutral\n",
      "  Baseline: negative (confidence: 35.21%) ✗\n",
      "\n",
      "Review 4: \"I was really excited about this dress, but the fabric feels ...\"\n",
      "  Expected: negative\n",
      "  Baseline: neutral (confidence: 35.02%) ✗\n",
      "\n",
      "Review 5: \"Have used this brand for decades and while it is our favorit...\"\n",
      "  Expected: negative\n",
      "  Baseline: negative (confidence: 36.32%) ✓\n",
      "\n",
      "Review 6: \"I'm really enjoying this blush. Application is smooth and ea...\"\n",
      "  Expected: positive\n",
      "  Baseline: neutral (confidence: 34.50%) ✗\n",
      "\n",
      "Review 7: \"Went to the beach with this water bottle full of ice. By 2pm...\"\n",
      "  Expected: negative\n",
      "  Baseline: negative (confidence: 36.94%) ✓\n",
      "\n",
      "Review 8: \"Beautiful sweater but runs very small. Had to return for a l...\"\n",
      "  Expected: neutral\n",
      "  Baseline: neutral (confidence: 35.43%) ✓\n"
     ]
    }
   ],
   "source": [
    "baseline_results = []\n",
    "\n",
    "#Reviews accuracy of predictions for currated reviews before any fine-tuning\n",
    "for i, (review, expected) in enumerate(zip(TEST_REVIEWS, EXPECTED_LABELS), 1):\n",
    "    result = predict_sentiment(baseline_model, review)\n",
    "    baseline_results.append(result)\n",
    "\n",
    "    match = \"✓\" if result[\"label\"] == expected else \"✗\"\n",
    "\n",
    "    print(f\"\\nReview {i}: \\\"{review[:60]}...\\\"\")\n",
    "    print(f\"  Expected: {expected}\")\n",
    "    print(f\"  Baseline: {result['label']} (confidence: {result['confidence']:.2%}) {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06PPyHv3M3RV",
    "outputId": "db1c99f4-ec3b-4068-82b1-3ba7f2fb97ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Accuracy: 4/8 = 50.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate baseline accuracy\n",
    "baseline_predictions = [r[\"label\"] for r in baseline_results]\n",
    "baseline_correct = sum(1 for pred, exp in zip(baseline_predictions, EXPECTED_LABELS) if pred == exp)\n",
    "baseline_accuracy = baseline_correct / len(EXPECTED_LABELS)\n",
    "\n",
    "print(f\"\\nBaseline Accuracy: {baseline_correct}/{len(EXPECTED_LABELS)} = {baseline_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W121rkjlM3RV"
   },
   "source": [
    "---\n",
    "\n",
    "# PART 2: Fine-Tuning\n",
    "\n",
    "Fine-tune the model on our e-commerce review dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAVDQuaBM3RV"
   },
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibOApDD3M3RV",
    "outputId": "71eb53b3-6586-40fe-b220-620ec0ec09ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n"
     ]
    }
   ],
   "source": [
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "train_enc = tokenize(X_train)\n",
    "val_enc = tokenize(X_val)\n",
    "test_enc = tokenize(X_test)\n",
    "\n",
    "print(\"Tokenization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8hiaKOLM3RV"
   },
   "source": [
    "## Build TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBTfeiBFM3RV",
    "outputId": "07902533-fe6f-48ac-efef-9b64fd8bc8d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 2263\n",
      "Val batches: 283\n",
      "Test batches: 283\n"
     ]
    }
   ],
   "source": [
    "#Combines encodings with labels, then shuffles and organizes them into batches of BATCH_SIZE\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (dict(train_enc), y_train)\n",
    ").shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (dict(val_enc), y_val)\n",
    ").batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (dict(test_enc), y_test)\n",
    ").batch(BATCH_SIZE)\n",
    "\n",
    "print(f\"Train batches: {len(train_ds)}\")\n",
    "print(f\"Val batches: {len(val_ds)}\")\n",
    "print(f\"Test batches: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_ClYlbOM3RW"
   },
   "source": [
    "## Load Fresh Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1XFosAa7M3RW",
    "outputId": "a4df6b92-d8ec-473f-a67a-a4edea17397f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded for fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "# Load a fresh copy of the pre-trained model for fine-tuning\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "print(\"Model loaded for fine-tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSHsDh21nEJ7"
   },
   "source": [
    "#### Freeze early layers to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fbzI6gHwnIx0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Froze encoder layer 0\n",
      "Froze encoder layer 1\n",
      "Froze encoder layer 2\n",
      "Froze encoder layer 3\n",
      "Froze encoder layer 4\n",
      "Froze encoder layer 5\n",
      "Frozen 6/12 encoder layers\n"
     ]
    }
   ],
   "source": [
    "NUM_LAYERS_TO_FREEZE = 6\n",
    "for i, layer in enumerate(model.roberta.encoder.layer[:NUM_LAYERS_TO_FREEZE]):\n",
    "    layer.trainable = False\n",
    "    print(f\"Froze encoder layer {i}\")\n",
    "\n",
    "print(f\"Frozen {NUM_LAYERS_TO_FREEZE}/12 encoder layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGHpxhQFM3RW",
    "outputId": "8594cdbe-d9ef-4624-b137-e34fb1ab97c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " roberta (TFRobertaMainLaye  multiple                  124055040 \n",
      " r)                                                              \n",
      "                                                                 \n",
      " classifier (TFRobertaClass  multiple                  592899    \n",
      " ificationHead)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124647939 (475.49 MB)\n",
      "Trainable params: 82120707 (313.27 MB)\n",
      "Non-trainable params: 42527232 (162.23 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrTndPHRM3RW",
    "outputId": "55c0c205-764b-46f5-a019-1f51eb14d1f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer blocks: 12\n",
      "tf_roberta_for_sequence_classification_1/classifier/dense/kernel:0 (768, 768)\n",
      "tf_roberta_for_sequence_classification_1/classifier/dense/bias:0 (768,)\n",
      "tf_roberta_for_sequence_classification_1/classifier/out_proj/kernel:0 (768, 3)\n",
      "tf_roberta_for_sequence_classification_1/classifier/out_proj/bias:0 (3,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transformer blocks: {model.config.num_hidden_layers}\")\n",
    "\n",
    "#For each weight layer in the classifier block\n",
    "for weight in model.classifier.weights:\n",
    "    print(weight.name, weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB5icm0CM3RW"
   },
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTBs0-s6M3RW",
    "outputId": "ebb32c60-4ba9-4961-a43f-f433c2ac7463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gelu\n"
     ]
    }
   ],
   "source": [
    "#What activation function is being used\n",
    "print(model.config.hidden_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7fWbEttM3RW"
   },
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxCw9ngqM3RW",
    "outputId": "190be6a7-2ac4-4aae-b3f6-0f495f4f9a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled with learning rate: 2e-05\n"
     ]
    }
   ],
   "source": [
    "from tf_keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(f\"Model compiled with learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuxPwW6LM3Ra"
   },
   "source": [
    "## Setup Callbacks\n",
    "Early stopping to stop early when val_loss falls for PATIENCE epochs, checkpoint to revert model to when the model had best val_loss, and reduce_lr to reduce learning rate when val_loss falls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shRBusP6M3Ra",
    "outputId": "671a0063-ed08-48fc-a043-9c0d7a9973b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks configured.\n"
     ]
    }
   ],
   "source": [
    "#Stop early if val_loss does not improve in PATIENCE epochs, to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#Revert to model when the epoch with best val_loss on finish\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=os.path.join(CHECKPOINT_DIR, \"best_model.keras\"),\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#Reduce learning rate when val_loss does not improve, to allow for more stable learning\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping]\n",
    "\n",
    "print(\"Callbacks configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JEATt9WM3Ra"
   },
   "source": [
    "## Train (Fine-Tune)\n",
    "Each epoch should take 10 minutes with GPU, and several hours without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pA_7wWkvM3Ra",
    "outputId": "d48bec76-df88-4a26-869a-9467794fe901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning for up to 3 epochs...\n",
      "============================================================\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767297847.978148  481581 service.cc:152] XLA service 0x78fcd9c95a30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1767297847.986650  481581 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2026-01-01 15:04:08.238204: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1767297848.351959  481581 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1767297848.698696  481581 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263/2263 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8512\n",
      "Epoch 1: val_loss improved from inf to 0.34078, saving model to runs/run_20260101_150332/checkpoints/best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carloslx/projects/cognizant/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263/2263 [==============================] - 415s 172ms/step - loss: 0.3471 - accuracy: 0.8512 - val_loss: 0.3408 - val_accuracy: 0.8546 - lr: 2.0000e-05\n",
      "Epoch 2/3\n",
      "2263/2263 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.8714\n",
      "Epoch 2: val_loss improved from 0.34078 to 0.33083, saving model to runs/run_20260101_150332/checkpoints/best_model.keras\n",
      "2263/2263 [==============================] - 364s 161ms/step - loss: 0.2934 - accuracy: 0.8714 - val_loss: 0.3308 - val_accuracy: 0.8515 - lr: 2.0000e-05\n",
      "Epoch 3/3\n",
      "2263/2263 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.8886\n",
      "Epoch 3: val_loss did not improve from 0.33083\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "2263/2263 [==============================] - 357s 158ms/step - loss: 0.2575 - accuracy: 0.8886 - val_loss: 0.3885 - val_accuracy: 0.8577 - lr: 2.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fine-tuning for up to {EPOCHS} epochs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"\\nFine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DFYqyCFM3Ra"
   },
   "source": [
    "### Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ua-wqBVM3Ra",
    "outputId": "e54d3b49-775e-4712-9e8a-e6ee52e86364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model saved to: runs/run_20260101_150332/models/final_model\n"
     ]
    }
   ],
   "source": [
    "final_model_path = os.path.join(MODEL_DIR, \"final_model\")\n",
    "model.save_pretrained(final_model_path)\n",
    "print(f\"\\nFinal model saved to: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EeViM5qM3Ra"
   },
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S42zeXL9M3Ra",
    "outputId": "47c1de79-22ff-4448-ebf1-6190398362cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 24s 85ms/step - loss: 0.3420 - accuracy: 0.8388\n",
      "\n",
      "Test Set Results:\n",
      "  Loss: 0.3420\n",
      "  Accuracy: 0.8388\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"\\nTest Set Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3IonWLVM3Rb"
   },
   "source": [
    "---\n",
    "\n",
    "# PART 3: Post-Training Evaluation (After Fine-Tuning)\n",
    "\n",
    "Same tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C_wvPfWM3Rb",
    "outputId": "0557c3ca-85e8-44c8-d6e8-095d80c77412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review 1: \"This is the worst product I've ever bought. Complete waste o...\"\n",
      "  Expected:   negative\n",
      "  Fine-tuned: negative (confidence: 96.01%) ✓\n",
      "\n",
      "Review 2: \"Absolutely love this dress! Perfect fit and beautiful fabric...\"\n",
      "  Expected:   positive\n",
      "  Fine-tuned: positive (confidence: 99.90%) ✓\n",
      "\n",
      "Review 3: \"This dress isn't really my style, but the fabric feels good ...\"\n",
      "  Expected:   neutral\n",
      "  Fine-tuned: positive (confidence: 76.14%) ✗\n",
      "\n",
      "Review 4: \"I was really excited about this dress, but the fabric feels ...\"\n",
      "  Expected:   negative\n",
      "  Fine-tuned: negative (confidence: 67.88%) ✓\n",
      "\n",
      "Review 5: \"Have used this brand for decades and while it is our favorit...\"\n",
      "  Expected:   negative\n",
      "  Fine-tuned: neutral (confidence: 51.12%) ✗\n",
      "\n",
      "Review 6: \"I'm really enjoying this blush. Application is smooth and ea...\"\n",
      "  Expected:   positive\n",
      "  Fine-tuned: positive (confidence: 99.89%) ✓\n",
      "\n",
      "Review 7: \"Went to the beach with this water bottle full of ice. By 2pm...\"\n",
      "  Expected:   negative\n",
      "  Fine-tuned: negative (confidence: 91.38%) ✓\n",
      "\n",
      "Review 8: \"Beautiful sweater but runs very small. Had to return for a l...\"\n",
      "  Expected:   neutral\n",
      "  Fine-tuned: positive (confidence: 57.72%) ✗\n"
     ]
    }
   ],
   "source": [
    "finetuned_results = []\n",
    "\n",
    "#Reviews accuracy of predictions for currated reviews after fine-tuning\n",
    "for i, (review, expected) in enumerate(zip(TEST_REVIEWS, EXPECTED_LABELS), 1):\n",
    "    result = predict_sentiment(model, review)\n",
    "    finetuned_results.append(result)\n",
    "\n",
    "    match = \"✓\" if result[\"label\"] == expected else \"✗\"\n",
    "\n",
    "    print(f\"\\nReview {i}: \\\"{review[:60]}...\\\"\")\n",
    "    print(f\"  Expected:   {expected}\")\n",
    "    print(f\"  Fine-tuned: {result['label']} (confidence: {result['confidence']:.2%}) {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlfek8nHM3Rb",
    "outputId": "d8cfebf1-12ec-4623-982b-9722c7cb81d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuned Accuracy: 5/8 = 62.5%\n"
     ]
    }
   ],
   "source": [
    "# Calculate fine-tuned accuracy\n",
    "finetuned_predictions = [r[\"label\"] for r in finetuned_results]\n",
    "finetuned_correct = sum(1 for pred, exp in zip(finetuned_predictions, EXPECTED_LABELS) if pred == exp)\n",
    "finetuned_accuracy = finetuned_correct / len(EXPECTED_LABELS)\n",
    "\n",
    "print(f\"\\nFine-tuned Accuracy: {finetuned_correct}/{len(EXPECTED_LABELS)} = {finetuned_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SElrBgJiM3Rb"
   },
   "source": [
    "---\n",
    "\n",
    "# PART 4: Before vs After Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUUdZSVhjX4c",
    "outputId": "b2629c36-a8ca-4687-da84-08ecf7d9978b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 36s 127ms/step - loss: 1.1735 - accuracy: 0.1325\n",
      "\n",
      "Test Results for Baseline Model:\n",
      "  Loss: 1.1735\n",
      "  Accuracy: 0.1325\n",
      "283/283 [==============================] - 35s 124ms/step - loss: 0.3420 - accuracy: 0.8388\n",
      "\n",
      "Test Results for Fine-Tuned Model:\n",
      "  Loss: 0.3420\n",
      "  Accuracy: 0.8388\n",
      "\n",
      "Difference in Basline and Fine-Tun:\n",
      "  Loss Difference: 0.8315\n",
      "  Accuracy Difference: 0.7063\n"
     ]
    }
   ],
   "source": [
    "baseline_test_loss, baseline_test_acc = baseline_model.evaluate(test_ds)\n",
    "\n",
    "print(f\"\\nTest Results for Baseline Model:\")\n",
    "print(f\"  Loss: {baseline_test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {baseline_test_acc:.4f}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"\\nTest Results for Fine-Tuned Model:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nDifference in Basline and Fine-Tun:\")\n",
    "print(f\"  Loss Difference: {(baseline_test_loss-test_loss):.4f}\")\n",
    "print(f\"  Accuracy Difference: {(test_acc-baseline_test_acc):.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
